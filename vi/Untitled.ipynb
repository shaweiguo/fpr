{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5690aff-a57b-455e-8988-e245912bb1f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d1cfab930d4719bba615bbf53263e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fengshen import RoFormerModel    \n",
    "from fengshen import RoFormerConfig\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"IDEA-CCNL/Zhouwenwang-Unified-1.3B\")\n",
    "config = RoFormerConfig.from_pretrained(\"IDEA-CCNL/Zhouwenwang-Unified-1.3B\")\n",
    "model = RoFormerModel.from_pretrained(\"IDEA-CCNL/Zhouwenwang-Unified-1.3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c88b04-b45d-42a2-8706-cd79155078d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sha/work/_p310/lib/python3.10/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Influenza is a highly contagious disease.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('IDEA-CCNL/Yuyuan-Bart-139M')\n",
    "model = BartForConditionalGeneration.from_pretrained('IDEA-CCNL/Yuyuan-Bart-139M')\n",
    "\n",
    "text = 'Influenza is a <mask> disease.'\n",
    "input_ids = tokenizer([text], return_tensors=\"pt\")['input_ids']\n",
    "model.eval()\n",
    "generated_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    ")\n",
    "preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "357995ff-c151-4623-b605-b220194f90b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Influenza is a highly contagious respiratory disease.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('IDEA-CCNL/Yuyuan-Bart-400M')\n",
    "model = BartForConditionalGeneration.from_pretrained('IDEA-CCNL/Yuyuan-Bart-400M')\n",
    "\n",
    "text = 'Influenza is a <mask> disease.'\n",
    "input_ids = tokenizer([text], return_tensors=\"pt\")['input_ids']\n",
    "model.eval()\n",
    "generated_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    ")\n",
    "preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "265d7137-3686-4ed6-9119-28c24bc189d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 20:19:41.267883: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of the model checkpoint at IDEA-CCNL/Yuyuan-GPT2-3.5B were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('IDEA-CCNL/Yuyuan-GPT2-3.5B')\n",
    "model = GPT2Model.from_pretrained('IDEA-CCNL/Yuyuan-GPT2-3.5B')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d35f55f7-ccc2-43f7-aca9-c7b91f667b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "YuyuanQA-GPT2-3.5B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/work/_p310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:264\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/work/_p310/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/YuyuanQA-GPT2-3.5B/resolve/main/vocab.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/work/_p310/lib/python3.10/site-packages/transformers/utils/hub.py:409\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m~/work/_p310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:124\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(\n\u001b[1;32m    121\u001b[0m         fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    122\u001b[0m     )\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:1106\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[0;32m~/work/_p310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:124\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(\n\u001b[1;32m    121\u001b[0m         fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    122\u001b[0m     )\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:1441\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1432\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1433\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1434\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   1440\u001b[0m )\n\u001b[0;32m-> 1441\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "File \u001b[0;32m~/work/_p310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:306\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    298\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m     )\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-63f0c28e-409f347d1d0184e3064400e5)\n\nRepository Not Found for url: https://huggingface.co/YuyuanQA-GPT2-3.5B/resolve/main/vocab.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2Tokenizer,GPT2LMHeadModel\n\u001b[1;32m      3\u001b[0m hf_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYuyuanQA-GPT2-3.5B\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mGPT2Tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhf_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m GPT2LMHeadModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(hf_model_path)\n",
      "File \u001b[0;32m~/work/_p310/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1763\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1761\u001b[0m             resolved_vocab_files[file_id] \u001b[38;5;241m=\u001b[39m download_url(file_path, proxies\u001b[38;5;241m=\u001b[39mproxies)\n\u001b[1;32m   1762\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1763\u001b[0m         resolved_vocab_files[file_id] \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1764\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1768\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1771\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1772\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1773\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1776\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1779\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_vocab_files[file_id], commit_hash)\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unresolved_files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/work/_p310/lib/python3.10/site-packages/transformers/utils/hub.py:424\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    409\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    410\u001b[0m         path_or_repo_id,\n\u001b[1;32m    411\u001b[0m         filename,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    420\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    421\u001b[0m     )\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[0;32m--> 424\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    425\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    435\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: YuyuanQA-GPT2-3.5B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer,GPT2LMHeadModel\n",
    "\n",
    "hf_model_path = 'YuyuanQA-GPT2-3.5B'\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(hf_model_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(hf_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "643b6e58-3f53-4122-88d7-5ab5ce64e16c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清华大学位于北京，枣庄是山东省8个重点支持建设的城市之一，受到了很大的关注，\n"
     ]
    }
   ],
   "source": [
    "from fengshen import RoFormerModel\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "sentence = '清华大学位于'\n",
    "max_length = 32\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"IDEA-CCNL/Zhouwenwang-Unified-1.3B\")\n",
    "model = RoFormerModel.from_pretrained(\"IDEA-CCNL/Zhouwenwang-Unified-1.3B\")\n",
    "\n",
    "for i in range(max_length):\n",
    "    encode = torch.tensor(\n",
    "        [[tokenizer.cls_token_id]+tokenizer.encode(sentence, add_special_tokens=False)]).long()\n",
    "    logits = model(encode)[0]\n",
    "    logits = torch.nn.functional.linear(\n",
    "        logits, model.embeddings.word_embeddings.weight)\n",
    "    logits = torch.nn.functional.softmax(\n",
    "        logits, dim=-1).cpu().detach().numpy()[0]\n",
    "    sentence = sentence + \\\n",
    "        tokenizer.decode(int(np.random.choice(logits.shape[1], p=logits[-1])))\n",
    "    if sentence[-1] == '。':\n",
    "        break\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8247bbd-e985-42d1-8d5a-f94142e7496c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清华大学位于浙江江江安安安安安安安安安安安安安安安安安安安安安安安安安安安安\n"
     ]
    }
   ],
   "source": [
    "from fengshen import RoFormerModel\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "sentence = '清华大学位于'\n",
    "max_length = 32\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"IDEA-CCNL/Zhouwenwang-Unified-110M\")\n",
    "model = RoFormerModel.from_pretrained(\"IDEA-CCNL/Zhouwenwang-Unified-110M\")\n",
    "\n",
    "for i in range(max_length):\n",
    "    encode = torch.tensor(\n",
    "        [[tokenizer.cls_token_id]+tokenizer.encode(sentence, add_special_tokens=False)]).long()\n",
    "    logits = model(encode)[0]\n",
    "    logits = torch.nn.functional.linear(\n",
    "        logits, model.embeddings.word_embeddings.weight)\n",
    "    logits = torch.nn.functional.softmax(\n",
    "        logits, dim=-1).cpu().detach().numpy()[0]\n",
    "    sentence = sentence + \\\n",
    "        tokenizer.decode(int(np.random.choice(logits.shape[1], p=logits[-1])))\n",
    "    if sentence[-1] == '。':\n",
    "        break\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fbdb345-b727-44d8-a1b9-fe902e04e3bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m processor \u001b[38;5;241m=\u001b[39m CLIPProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai/clip-vit-base-patch32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m image \u001b[38;5;241m=\u001b[39m processor(images\u001b[38;5;241m=\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(requests\u001b[38;5;241m.\u001b[39mget(url, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mraw), return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mimage_data\u001b[49m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     21\u001b[0m     image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_data' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import clip\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "\n",
    "query_texts = [\"一只猫\", \"一只狗\",'两只猫', '两只老虎','一只老虎']  # 这里是输入文本的，可以随意替换。\n",
    "# 加载Taiyi 中文 text encoder\n",
    "text_tokenizer = BertTokenizer.from_pretrained(\"IDEA-CCNL/Taiyi-CLIP-Roberta-102M-Chinese\")\n",
    "text_encoder = BertForSequenceClassification.from_pretrained(\"IDEA-CCNL/Taiyi-CLIP-Roberta-102M-Chinese\").eval()\n",
    "text = text_tokenizer(query_texts, return_tensors='pt', padding=True)['input_ids']\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"  # 这里可以换成任意图片的url\n",
    "# 加载CLIP的image encoder\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")  \n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "image = processor(images=Image.open(requests.get(url, stream=True).raw), return_tensors=\"pt\")\n",
    "if image_data.mode != 'RGB':\n",
    "    image = image.convert('RGB')\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = clip_model.get_image_features(**image)\n",
    "    text_features = text_encoder(text).logits\n",
    "    # 归一化\n",
    "    image_features = image_features / image_features.norm(dim=1, keepdim=True)\n",
    "    text_features = text_features / text_features.norm(dim=1, keepdim=True)\n",
    "    # 计算余弦相似度 logit_scale是尺度系数\n",
    "    logit_scale = clip_model.logit_scale.exp()\n",
    "    logits_per_image = logit_scale * image_features @ text_features.t()\n",
    "    logits_per_text = logits_per_image.t()\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "    print(np.around(probs, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4dbdee-7d91-4ca7-a727-136d78055c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m processor \u001b[38;5;241m=\u001b[39m CLIPProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai/clip-vit-large-patch14\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m image \u001b[38;5;241m=\u001b[39m processor(images\u001b[38;5;241m=\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(requests\u001b[38;5;241m.\u001b[39mget(url, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mraw), return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mimage_data\u001b[49m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     21\u001b[0m     image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_data' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import clip\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "\n",
    "query_texts = [\"一只猫\", \"一只狗\",'两只猫', '两只老虎','一只老虎']  # 这里是输入文本的，可以随意替换。\n",
    "# 加载Taiyi 中文 text encoder\n",
    "text_tokenizer = BertTokenizer.from_pretrained(\"IDEA-CCNL/Taiyi-CLIP-Roberta-large-326M-Chinese\")\n",
    "text_encoder = BertForSequenceClassification.from_pretrained(\"IDEA-CCNL/Taiyi-CLIP-Roberta-large-326M-Chinese\").eval()\n",
    "text = text_tokenizer(query_texts, return_tensors='pt', padding=True)['input_ids']\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"  # 这里可以换成任意图片的url\n",
    "# 加载CLIP的image encoder\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")  \n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "image = processor(images=Image.open(requests.get(url, stream=True).raw), return_tensors=\"pt\")\n",
    "if image_data.mode != 'RGB':\n",
    "    image = image.convert('RGB')\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = clip_model.get_image_features(**image)\n",
    "    text_features = text_encoder(text).logits\n",
    "    # 归一化\n",
    "    image_features = image_features / image_features.norm(dim=1, keepdim=True)\n",
    "    text_features = text_features / text_features.norm(dim=1, keepdim=True)\n",
    "    # 计算余弦相似度 logit_scale是尺度系数\n",
    "    logit_scale = clip_model.logit_scale.exp()\n",
    "    logits_per_image = logit_scale * image_features @ text_features.t()\n",
    "    logits_per_text = logits_per_image.t()\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "    print(np.around(probs, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a4cea67-89f1-4a52-9575-23c0fc0a944d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"IDEA-CCNL/Taiyi-Roberta-124M-D-v2\")\n",
    "model = RobertaModel.from_pretrained(\"IDEA-CCNL/Taiyi-Roberta-124M-D-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a242af54-c0c9-4aa3-9384-6859f2468ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"IDEA-CCNL/Taiyi-Roberta-124M-D\")\n",
    "model = RobertaModel.from_pretrained(\"IDEA-CCNL/Taiyi-Roberta-124M-D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99b76d26-f66e-43c2-830f-fb8ac4627efc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sha/work/_p310/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Egyptian cat\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('IDEA-CCNL/Taiyi-vit-87M-D')\n",
    "model = ViTForImageClassification.from_pretrained('IDEA-CCNL/Taiyi-vit-87M-D')\n",
    "\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])\n",
    "# Predicted class: Egyptian cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a1b0ae6-8bd1-4246-a016-18e20ac2a0d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '谷爱凌获自由式滑雪女子坡面障碍技巧银牌'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, AutoTokenizer, Text2TextGenerationPipeline\n",
    "import torch\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained('IDEA-CCNL/Randeng-BART-139M-SUMMARY')\n",
    "model=BartForConditionalGeneration.from_pretrained('IDEA-CCNL/Randeng-BART-139M-SUMMARY')\n",
    "text = 'summary:在北京冬奥会自由式滑雪女子坡面障碍技巧决赛中，中国选手谷爱凌夺得银牌。祝贺谷爱凌！今天上午，自由式滑雪女子坡面障碍技巧决赛举行。决赛分三轮进行，取选手最佳成绩排名决出奖牌。第一跳，中国选手谷爱凌获得69.90分。在12位选手中排名第三。完成动作后，谷爱凌又扮了个鬼脸，甚是可爱。第二轮中，谷爱凌在道具区第三个障碍处失误，落地时摔倒。获得16.98分。网友：摔倒了也没关系，继续加油！在第二跳失误摔倒的情况下，谷爱凌顶住压力，第三跳稳稳发挥，流畅落地！获得86.23分！此轮比赛，共12位选手参赛，谷爱凌第10位出场。网友：看比赛时我比谷爱凌紧张，加油！'\n",
    "text2text_generator = Text2TextGenerationPipeline(model, tokenizer)\n",
    "print(text2text_generator(text, max_length=50, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "756bb3d9-50b9-4d65-b22b-c30e30b0b4d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968e4620f73947d4a785bde4b37c8278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"spiece.model\";:   0%|          | 0.00/859k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0464e97458824077a0ca2cea77df784c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/33.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10fa9fb3942644ccad33b9273d03a805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/157 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae800dabbb564bb997370b8758950588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76aa1dfe4b664ff684353d3390a90333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/279M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '桂林市是世界闻名遐迩的旅游城市 ,它有悠久的旅游历史。'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, AutoTokenizer, Text2TextGenerationPipeline\n",
    "import torch\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained('IDEA-CCNL/Randeng-BART-139M', use_fast=False)\n",
    "model=BartForConditionalGeneration.from_pretrained('IDEA-CCNL/Randeng-BART-139M')\n",
    "text = '<s>桂林市是世界闻名<mask> ，它有悠久的<mask>'\n",
    "text2text_generator = Text2TextGenerationPipeline(model, tokenizer)\n",
    "print(text2text_generator(text, max_length=50, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95bcc536-0c70-456f-bd4b-7f24d1884849",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '桂 林 是 著 名 的 旅 游 城 市 ， 它 有 很 多 景 点 。'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, AutoTokenizer, Text2TextGenerationPipeline\n",
    "import torch\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained('IDEA-CCNL/Randeng-BART-759M-Chinese-BertTokenizer', use_fast=False)\n",
    "model=BartForConditionalGeneration.from_pretrained('IDEA-CCNL/Randeng-BART-759M-Chinese-BertTokenizer')\n",
    "text = '桂林是著名的[MASK]，它有很多[MASK]。'\n",
    "text2text_generator = Text2TextGenerationPipeline(model, tokenizer)\n",
    "print(text2text_generator(text, max_length=50, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c280e7a-8550-4d2a-ac1d-b12556856b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-19 10:16:14.179791: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cached_path' from 'transformers.utils' (/home/sha/work/_p310/lib/python3.10/site-packages/transformers/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfengshen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDAVAE\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDAVAEModel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DAVAEModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer,T5Tokenizer\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/src/Fengshenbang-LM/fengshen/models/DAVAE/DAVAEModel.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cached_path,hf_bucket_url\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfengshen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDAVAE\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mGPT2ModelForLatent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2ModelForLatent\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfengshen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDAVAE\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mBertForLatentConnector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertForLatentConnector\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'cached_path' from 'transformers.utils' (/home/sha/work/_p310/lib/python3.10/site-packages/transformers/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from fengshen.models.DAVAE.DAVAEModel import DAVAEModel\n",
    "from transformers import BertTokenizer,T5Tokenizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder_tokenizer = BertTokenizer.from_pretrained(\"IDEA-CCNL/Randeng-DAVAE-1.2B-General-Chinese\")\n",
    "decoder_tokenizer = T5Tokenizer.from_pretrained(\"IDEA-CCNL/Randeng-DAVAE-1.2B-General-Chinese\", eos_token = '<|endoftext|>', pad_token = '<pad>',extra_ids=0)\n",
    "decoder_tokenizer.add_special_tokens({'bos_token':'<bos>'})\n",
    "vae_model = DAVAEModel.from_pretrained(\"IDEA-CCNL/Randeng-DAVAE-1.2B-General-Chinese\").to(device)\n",
    "input_texts = [\n",
    "    \"针对电力系统中的混沌振荡对整个互联电网的危害问题,提出了一种基于非线性光滑函数的滑模控制方法.\",\n",
    "    \"超市面积不算大.挺方便附近的居民购买的. 生活用品也比较齐全.价格适用中.\",\n",
    "]\n",
    "output_texts = vae_model.simulate_batch(encoder_tokenizer,decoder_tokenizer,input_texts)\n",
    "print(output_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad61592-e1e2-4020-aef2-b06a3def81ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_sent: <BOS>本模型是在通用数据集下预训练的[UNK]模型，如要获得最佳效果请在特定领域微调后使用。<EOS>\n",
      "gen_sent: <BOS>本模式是通过在预备模式下数据集的数据集，模型本身也是通过电脑与微软的模型集训，最为可以用来预备某一下功夫在训练模式下的发明和应用之一，因为大家想要解决这一点点功能集训只能在数据下点。[UNK]<EOS>\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Checkout the latest Fengshenbang-LM directory and run following script under Fengshenbang-LM root directory \n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from fengshen.models.deepVAE.deep_vae import Della\n",
    "from transformers.models.bert.tokenization_bert import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"IDEA-CCNL/Randeng-DELLA-226M-Chinese\")\n",
    "vae_model = Della.from_pretrained(\"IDEA-CCNL/Randeng-DELLA-226M-Chinese\")\n",
    "special_tokens_dict = {'bos_token': '<BOS>', 'eos_token': '<EOS>'}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "sentence =  \"本模型是在通用数据集下预训练的VAE模型，如要获得最佳效果请在特定领域微调后使用。\"\n",
    "tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentence))\n",
    "decoder_target = [tokenizer.bos_token_id] + tokenized_text + [tokenizer.eos_token_id]\n",
    "inputs = []\n",
    "inputs.append(torch.tensor(decoder_target, dtype=torch.long))\n",
    "inputs = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "max_length = 256\n",
    "top_p = 0.5\n",
    "top_k = 0\n",
    "temperature = .7\n",
    "repetition_penalty = 1.0\n",
    "sample = False\n",
    "device = 0\n",
    "model = vae_model.eval()\n",
    "model = model.to(device)\n",
    "outputs = model.model.inference(inputs.to(device), top_p=top_p, top_k=top_k, max_length=max_length, sample=sample,\n",
    "    temperature=temperature, repetition_penalty=repetition_penalty)\n",
    "for gen_sent, orig_sent in zip(outputs, inputs):\n",
    "    print('orig_sent:', tokenizer.decode(orig_sent).replace(' ', ''))\n",
    "    print('gen_sent:', tokenizer.decode(gen_sent).replace(' ', ''))\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e232b6-dd3c-4e64-99b4-58ad4a8cc549",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cached_path' from 'transformers.utils' (/home/sha/work/_p310/lib/python3.10/site-packages/transformers/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer,T5Tokenizer\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfengshen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mGAVAE\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mGAVAEModel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GAVAEModel\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m input_texts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m非常好的一个博物馆，是我所有去过的博物馆里感觉最正规的一家，凭有效证件可以入馆，可以自助免费存小件物品，讲解员和馆内外的工作人员也非常认真，其他的服务人员也很热情，非常好的！馆内的藏品也让人非常震撼！希望继续保持～\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m这是我来长沙最最期待的一定要去的地方，总算今天特地去瞻仰千古遗容了，开车到门口大屏幕显示着门票已发完的字样，心里一惊以为今天是白来了。但进了停车场才知道凭停车卡和有效身份证里面也能领，停车还不花钱，真好。\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m网上订票去的，还是很顺利的就进去了，里面挺清净的，外围的环境也不错，还有鸽子可以喂。那天不是很闹，兜了一圈感觉还是很顺畅的，老娘娘和金缕玉衣挺震撼的。到此一游还是挺需要的\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m ]\n",
      "File \u001b[0;32m~/src/Fengshenbang-LM/fengshen/models/GAVAE/GAVAEModel.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfengshen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDAVAE\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDAVAEModel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DAVAEModel\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfengshen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mGAVAE\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgans_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gans_process\n\u001b[1;32m     28\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/src/Fengshenbang-LM/fengshen/models/DAVAE/DAVAEModel.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cached_path,hf_bucket_url\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfengshen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDAVAE\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mGPT2ModelForLatent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2ModelForLatent\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfengshen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDAVAE\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mBertForLatentConnector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertForLatentConnector\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'cached_path' from 'transformers.utils' (/home/sha/work/_p310/lib/python3.10/site-packages/transformers/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer,T5Tokenizer\n",
    "from fengshen.models.GAVAE.GAVAEModel import GAVAEModel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_texts = [\n",
    "    \"非常好的一个博物馆，是我所有去过的博物馆里感觉最正规的一家，凭有效证件可以入馆，可以自助免费存小件物品，讲解员和馆内外的工作人员也非常认真，其他的服务人员也很热情，非常好的！馆内的藏品也让人非常震撼！希望继续保持～\", \n",
    "    \"这是我来长沙最最期待的一定要去的地方，总算今天特地去瞻仰千古遗容了，开车到门口大屏幕显示着门票已发完的字样，心里一惊以为今天是白来了。但进了停车场才知道凭停车卡和有效身份证里面也能领，停车还不花钱，真好。\", \n",
    "    \"地方很大 很气派~~可以逛很久~~~去的时候是免费的~不过要安检~~~里面的马王堆~幸追夫人~还是很不错的~~~~去的时候有一个吴越文化特别展~~~东西也很多~~~~~很好看\",\n",
    "    \"我们到达的时候是下午3点，门票已经发完了。当时正焦虑的不知道怎么办才好，门卫大哥给我们俩补办了门票，这才得以入馆。非常感谢！绝对不虚此行！相当震撼的展览！原来古人也化妆，还有假发。记忆最深的是那个藕汤。可惜真颜已不得见。\", \n",
    "    \"去过三次，个人认为这是长沙最值得去的地方，博物馆的重点就是辛追，遗憾的是，每次去我都会感到悲哀，虽然我三次去的时候都要门票，但是每次看到辛追，都觉得现代的人类不应该挖她出来，除了第一次我觉得辛追像刚死去一样，后来两次我觉得太惨不忍睹了。建议大家要去就早去，以后肯定越来越腐烂\", \n",
    "    \"上大学时候去的，当时学生证是半价25，后来凭有效证件就不要钱了。非常喜欢的一家博物馆，里面可看的东西很多，当然最吸引我的就是那个辛追夫人和“素纱单衣”，果然不是盖的~里面的讲解员大部分都是师大学历史类的，非常专业和有耐心。虽然不在长沙了，不过对那里还是很有感情的，赞~~~\", \n",
    "    \"这两年也有很多机会去博物馆。。。不过还是想说湖南省博物馆是非常有特色的。。。应该说整个展览分成两个部分吧。。。一个部分是马王堆的主体展。。。另一个就是湖南的一些考古发现。。。其实来省博大部分的游客还是冲着马王堆来的吧。。。博物馆也很有心的为每一批游客安排了讲解员。。。从马王堆的发现到马王堆出土文物的介绍再到最后棺木和辛追的介绍。。。真是上了一节很生动的历史课。\",\n",
    "    \"网上订票去的，还是很顺利的就进去了，里面挺清净的，外围的环境也不错，还有鸽子可以喂。那天不是很闹，兜了一圈感觉还是很顺畅的，老娘娘和金缕玉衣挺震撼的。到此一游还是挺需要的\",\n",
    "]\n",
    "encoder_tokenizer = BertTokenizer.from_pretrained(\"IDEA-CCNL/Randeng-GAVAE-1.2B-Augmentation-Chinese\")\n",
    "decoder_tokenizer = T5Tokenizer.from_pretrained(\"IDEA-CCNL/Randeng-GAVAE-1.2B-Augmentation-Chinese\", eos_token = '<|endoftext|>', pad_token = '<pad>',extra_ids=0)\n",
    "decoder_tokenizer.add_special_tokens({'bos_token':'<bos>'})\n",
    "gavae_model = GAVAEModel.from_pretrained(\"IDEA-CCNL/Randeng-GAVAE-1.2B-Augmentation-Chinese\").to(device)\n",
    "gavae_model.train_gan(encoder_tokenizer,decoder_tokenizer,input_texts)\n",
    "# n:输出样本数量\n",
    "texts = gavae_model.generate(n=5)\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c047bdd-b0f2-4c4a-a208-7325ff8b96fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fengshen import T5ForConditionalGeneration\n",
    "from fengshen import T5Config\n",
    "from fengshen import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('IDEA-CCNL/Randeng-MegatronT5-770M')\n",
    "config = T5Config.from_pretrained('IDEA-CCNL/Randeng-MegatronT5-770M')\n",
    "model = T5ForConditionalGeneration.from_pretrained('IDEA-CCNL/Randeng-MegatronT5-770M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56870c49-52d8-4c9c-ad4b-059cb5bf4597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration\n",
    "# Need to download tokenizers_pegasus.py and other Python script from Fengshenbang-LM github repo in advance,\n",
    "# or you can download tokenizers_pegasus.py and data_utils.py in https://huggingface.co/IDEA-CCNL/Randeng_Pegasus_238M/tree/main\n",
    "# Stronly recomend you git clone the Fengshenbang-LM repo:\n",
    "# 1. git clone https://github.com/IDEA-CCNL/Fengshenbang-LM\n",
    "# 2. cd Fengshenbang-LM/fengshen/examples/pegasus/\n",
    "# and then you will see the tokenizers_pegasus.py and data_utils.py which are needed by pegasus model\n",
    "from tokenizers_pegasus import PegasusTokenizer\n",
    "\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"IDEA-CCNL/Randeng-Pegasus-238M-Chinese\")\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"IDEA-CCNL/Randeng-Pegasus-238M-Chinese\")\n",
    "\n",
    "text = \"据微信公众号“界面”报道，4日上午10点左右，中国发改委反垄断调查小组突击查访奔驰上海办事处，调取数据材料，并对多名奔驰高管进行了约谈。截止昨日晚9点，包括北京梅赛德斯-奔驰销售服务有限公司东区总经理在内的多名管理人员仍留在上海办公室内\"\n",
    "inputs = tokenizer(text, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"])\n",
    "tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "# model output: 截止昨日晚9点，包括北京梅赛德斯-奔驰销售服务有限公司东区总经理在内的多名管理人员仍留在上海办公室内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd8b2e3-6917-4964-bde5-dfe90f56935f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration,BertTokenizer\n",
    "# Need to download tokenizers_pegasus.py and other Python script from Fengshenbang-LM github repo in advance,\n",
    "# or you can download tokenizers_pegasus.py and data_utils.py in https://huggingface.co/IDEA-CCNL/Randeng_Pegasus_523M/tree/main\n",
    "# Strongly recommend you git clone the Fengshenbang-LM repo:\n",
    "# 1. git clone https://github.com/IDEA-CCNL/Fengshenbang-LM\n",
    "# 2. cd Fengshenbang-LM/fengshen/examples/pegasus/\n",
    "# and then you will see the tokenizers_pegasus.py and data_utils.py which are needed by pegasus model\n",
    "\n",
    "from tokenizers_pegasus import PegasusTokenizer\n",
    "\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese\")\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese\")\n",
    "\n",
    "text = \"在北京冬奥会自由式滑雪女子坡面障碍技巧决赛中，中国选手谷爱凌夺得银牌。祝贺谷爱凌！今天上午，自由式滑雪女子坡面障碍技巧决赛举行。决赛分三轮进行，取选手最佳成绩排名决出奖牌。第一跳，中国选手谷爱凌获得69.90分。在12位选手中排名第三。完成动作后，谷爱凌又扮了个鬼脸，甚是可爱。第二轮中，谷爱凌在道具区第三个障碍处失误，落地时摔倒。获得16.98分。网友：摔倒了也没关系，继续加油！在第二跳失误摔倒的情况下，谷爱凌顶住压力，第三跳稳稳发挥，流畅落地！获得86.23分！此轮比赛，共12位选手参赛，谷爱凌第10位出场。网友：看比赛时我比谷爱凌紧张，加油！\"\n",
    "inputs = tokenizer(text, max_length=1024, return_tensors=\"pt\")\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"])\n",
    "tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "\n",
    "# model Output: 滑雪女子坡面障碍技巧决赛谷爱凌获银牌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875befc6-85b1-4018-b3c6-e09f6ddd1f4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration\n",
    "# Need to download tokenizers_pegasus.py and other Python script from Fengshenbang-LM github repo in advance,\n",
    "# or you can download tokenizers_pegasus.py and data_utils.py in https://huggingface.co/IDEA-CCNL/Randeng_Pegasus_523M/tree/main\n",
    "# Strongly recommend you git clone the Fengshenbang-LM repo:\n",
    "# 1. git clone https://github.com/IDEA-CCNL/Fengshenbang-LM\n",
    "# 2. cd Fengshenbang-LM/fengshen/examples/pegasus/\n",
    "# and then you will see the tokenizers_pegasus.py and data_utils.py which are needed by pegasus model\n",
    "from tokenizers_pegasus import PegasusTokenizer\n",
    "\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"IDEA-CCNL/Randeng-Pegasus-523M-Chinese\")\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"IDEA-CCNL/Randeng-Pegasus-523M-Chinese\")\n",
    "\n",
    "text = \"据微信公众号“界面”报道，4日上午10点左右，中国发改委反垄断调查小组突击查访奔驰上海办事处，调取数据材料，并对多名奔驰高管进行了约谈。截止昨日晚9点，包括北京梅赛德斯-奔驰销售服务有限公司东区总经理在内的多名管理人员仍留在上海办公室内\"\n",
    "inputs = tokenizer(text, max_length=1024, return_tensors=\"pt\")\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"])\n",
    "tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "\n",
    "# model Output: 截止昨日晚9点，包括北京梅赛德斯-奔驰销售服务有限公司东区总经理在内的多名管理人员仍留在上海办公室内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b385b2-9db1-4da2-80a7-da49e72f5419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration\n",
    "# Need to download tokenizers_pegasus.py and other Python script from Fengshenbang-LM github repo in advance,\n",
    "# or you can download tokenizers_pegasus.py and data_utils.py in https://huggingface.co/IDEA-CCNL/Randeng_Pegasus_523M/tree/main\n",
    "# Strongly recommend you git clone the Fengshenbang-LM repo:\n",
    "# 1. git clone https://github.com/IDEA-CCNL/Fengshenbang-LM\n",
    "# 2. cd Fengshenbang-LM/fengshen/examples/pegasus/\n",
    "# and then you will see the tokenizers_pegasus.py and data_utils.py which are needed by pegasus model\n",
    "from tokenizers_pegasus import PegasusTokenizer\n",
    "\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese\")\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese\")\n",
    "\n",
    "text = \"据微信公众号“界面”报道，4日上午10点左右，中国发改委反垄断调查小组突击查访奔驰上海办事处，调取数据材料，并对多名奔驰高管进行了约谈。截止昨日晚9点，包括北京梅赛德斯-奔驰销售服务有限公司东区总经理在内的多名管理人员仍留在上海办公室内\"\n",
    "inputs = tokenizer(text, max_length=1024, return_tensors=\"pt\")\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"])\n",
    "tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "\n",
    "# model Output: 反垄断调查小组突击查访奔驰上海办事处，对多名奔驰高管进行约谈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1839c-8df8-4c67-bea5-e400b9983c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer,T5Tokenizer\n",
    "from fengshen.models.PPVAE.pluginVAE import PPVAEModel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_texts = [\n",
    "    \"非常好的一个博物馆，是我所有去过的博物馆里感觉最正规的一家.\", \n",
    "    \"这是我来长沙最最期待的一定要去的地方，总算今天特地去瞻仰千古遗容了，真好。\", \n",
    "    \"地方很大 很气派~~可以逛很久~~~去的时候是免费的~不过要安检~~~里面的马王堆~幸追夫人~还是很不错的\",\n",
    "    \"绝对不虚此行！相当震撼的展览！原来古人也化妆，还有假发。记忆最深的是那个藕汤。可惜真颜已不得见。\", \n",
    "    \"去过三次，个人认为这是长沙最值得去的地方.\", \n",
    "    \"非常喜欢的一家博物馆，里面可看的东西很多，当然最吸引我的就是那个辛追夫人和“素纱单衣”，果然不是盖的~赞~~~\", \n",
    "    \"这两年也有很多机会去博物馆。。。不过还是想说湖南省博物馆是非常有特色的。。。真是上了一节很生动的历史课。\",\n",
    "    \"网上订票去的，还是很顺利的就进去了，里面挺清净的，外围的环境也不错，还有鸽子可以喂。\",\n",
    "]\n",
    "encoder_tokenizer = BertTokenizer.from_pretrained(\"IDEA-CCNL/Randeng-PPVAE-1.2B-General-Chinese\")\n",
    "decoder_tokenizer = T5Tokenizer.from_pretrained(\"IDEA-CCNL/Randeng-PPVAE-1.2B-General-Chinese\", eos_token = '<|endoftext|>', pad_token = '<pad>',extra_ids=0)\n",
    "decoder_tokenizer.add_special_tokens({'bos_token':'<bos>'})\n",
    "ppvae_model = PPVAEModel.from_pretrained(\"IDEA-CCNL/Randeng-PPVAE-1.2B-Augmentation-Chinese\").to(device)\n",
    "ppvae_model.train_plugin(encoder_tokenizer,decoder_tokenizer,input_texts,negative_samples=None)\n",
    "# n:输出样本数量\n",
    "texts = ppvae_model.generate(n=5)\n",
    "print(texts)\n",
    "# 生成结果样例：\n",
    "# ['同学很推荐那里,自然会有好的风景.那里物价很便宜,真的不错。', \n",
    "# '同学说一会去盛国,可能是我去的比较多!故居真的很漂亮,夜景也特别好看。'\n",
    "# '我的第一次旅行没有白来,最后领略了有些风吹草低见牛羊的味道,谢谢本次疗养。', \n",
    "# '同学一打听:这里距离世纪公园,还有最近的香山营不过200米,海拔也才四千米。', \n",
    "# '我发现那边很文艺!!有机会去过的,真是土耳其当地口音~还是很干净!。', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4c567a-0001-440d-8269-624a6eb966fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fengshen.models.transfo_xl_denoise.tokenization_transfo_xl_denoise import TransfoXLDenoiseTokenizer\n",
    "from fengshen.models.transfo_xl_denoise.modeling_transfo_xl_denoise import TransfoXLDenoiseModel\n",
    "\n",
    "tokenizer = TransfoXLDenoiseTokenizer.from_pretrained('IDEA-CCNL/Randeng-Transformer-1.1B-Denoise')\n",
    "model = TransfoXLDenoiseModel.from_pretrained('IDEA-CCNL/Randeng-Transformer-1.1B-Denoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc113301-cdd1-4d79-83fc-c5362574e4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fengshen.models.transfo_xl_reasoning import TransfoXLModel\n",
    "from transformers import T5Tokenizer as TransfoXLTokenizer\n",
    "\n",
    "model = TransfoXLModel.from_pretrained('IDEA-CCNL/Randeng-TransformerXL-5B-Deduction-Chinese')\n",
    "tokenizer = TransfoXLTokenizer.from_pretrained(\n",
    "    \"IDEA-CCNL/Randeng-TransformerXL-5B-Deduction-Chinese\",\n",
    "    eos_token='<|endoftext|>',\n",
    "    pad_token='<|endoftext|>',\n",
    "    extra_ids=0\n",
    ")\n",
    "tokenizer.add_special_tokens({'bos_token': '<bos>'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba6fa267-5d77-4771-a666-6cc384b93606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d4955c706b4f11b1513f218de9419a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"spiece.model\";:   0%|          | 0.00/1.02M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fengshen.models.transfo_xl_reasoning import TransfoXLModel\n",
    "from transformers import T5Tokenizer as TransfoXLTokenizer\n",
    "\n",
    "model = TransfoXLModel.from_pretrained('IDEA-CCNL/Randeng-TransformerXL-5B-Abduction-Chinese')\n",
    "tokenizer = TransfoXLTokenizer.from_pretrained(\n",
    "    \"IDEA-CCNL/Randeng-TransformerXL-5B-Abduction-Chinese\",\n",
    "    eos_token='<|endoftext|>',\n",
    "    pad_token='<|endoftext|>',\n",
    "    extra_ids=0\n",
    ")\n",
    "tokenizer.add_special_tokens({'bos_token': '<bos>'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8179f24d-0e9b-4409-bcc1-6a9caaf9932f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 22:08:50.086849: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained('IDEA-CCNL/Randeng-T5-77M', use_fast=False)\n",
    "model=T5ForConditionalGeneration.from_pretrained('IDEA-CCNL/Randeng-T5-77M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41f6dbbc-39d9-461c-a2e9-5ce5bb2b4e31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028462c7e24a4fa49a92e6621834362f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.57G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "import torch\n",
    "tokenizer=AutoTokenizer.from_pretrained('IDEA-CCNL/Randeng-T5-784M', use_fast=False)\n",
    "model=T5ForConditionalGeneration.from_pretrained('IDEA-CCNL/Randeng-T5-784M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1193ebc8-027a-4650-adf7-332969424d57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('IDEA-CCNL/Wenzhong-GPT2-3.5B')\n",
    "model = GPT2Model.from_pretrained('IDEA-CCNL/Wenzhong-GPT2-3.5B')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc832051-ed39-47ac-9007-76da515310ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer,GPT2LMHeadModel\n",
    "hf_model_path = 'IDEA-CCNL/Wenzhong-GPT2-110M'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(hf_model_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(hf_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40321b8f-61db-428d-855b-c858ab3771e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('IDEA-CCNL/Wenzhong2.0-GPT2-3.5B-chinese')\n",
    "model = GPT2Model.from_pretrained('IDEA-CCNL/Wenzhong2.0-GPT2-3.5B-chinese')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb7d499-0b98-44d9-a2ed-af309080b476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer, FillMaskPipeline\n",
    "import torch\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained('IDEA-CCNL/Erlangshen-DeBERTa-v2-97M-Chinese', use_fast=False)\n",
    "model=AutoModelForMaskedLM.from_pretrained('IDEA-CCNL/Erlangshen-DeBERTa-v2-97M-Chinese')\n",
    "text = '生活的真谛是[MASK]。'\n",
    "fillmask_pipe = FillMaskPipeline(model, tokenizer, device=7)\n",
    "print(fillmask_pipe(text, top_k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bc8002-8df5-4ee2-be07-8754fb77ab7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer, FillMaskPipeline\n",
    "import torch\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained('IDEA-CCNL/Erlangshen-DeBERTa-v2-97M-Chinese', use_fast=False)\n",
    "model=AutoModelForMaskedLM.from_pretrained('IDEA-CCNL/Erlangshen-DeBERTa-v2-97M-Chinese')\n",
    "text = '生活的真谛是[MASK]。'\n",
    "fillmask_pipe = FillMaskPipeline(model, tokenizer, device=7)\n",
    "print(fillmask_pipe(text, top_k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c91040-80ab-4bb3-984d-1ba4104da4f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer, FillMaskPipeline\n",
    "import torch\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained('IDEA-CCNL/Erlangshen-DeBERTa-v2-97M-CWS-Chinese', use_fast=False)\n",
    "model=AutoModelForMaskedLM.from_pretrained('IDEA-CCNL/Erlangshen-DeBERTa-v2-97M-CWS-Chinese')\n",
    "text = '生活的真谛是[MASK]。'\n",
    "fillmask_pipe = FillMaskPipeline(model, tokenizer, device=7)\n",
    "print(fillmask_pipe(text, top_k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "814ed38e-0ca8-495b-93af-a185a516c911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.5303832292556763, 'token': 166, 'token_str': '北京', 'sequence': '中国首都位于北京 。'}, {'score': 0.23851409554481506, 'token': 119214, 'token_str': '首都北京', 'sequence': '中国首都位于首都北京 。'}, {'score': 0.05661068856716156, 'token': 2317, 'token_str': '北京', 'sequence': '中国首都位于 北京 。'}, {'score': 0.02194885164499283, 'token': 2922, 'token_str': '北京市', 'sequence': '中国首都位于北京市 。'}, {'score': 0.01590009778738022, 'token': 55805, 'token_str': '北京市朝阳区', 'sequence': '中国首都位于北京市朝阳区 。'}, {'score': 0.006819294765591621, 'token': 2071, 'token_str': '西安', 'sequence': '中国首都位于西安 。'}, {'score': 0.005462943576276302, 'token': 4361, 'token_str': '在北京', 'sequence': '中国首都位于在北京 。'}, {'score': 0.005386651027947664, 'token': 1858, 'token_str': '天津', 'sequence': '中国首都位于天津 。'}, {'score': 0.004599474370479584, 'token': 1386, 'token_str': '广州', 'sequence': '中国首都位于广州 。'}, {'score': 0.004495302215218544, 'token': 1418, 'token_str': '南京', 'sequence': '中国首都位于南京 。'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer, FillMaskPipeline\n",
    "import torch\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained('IDEA-CCNL/Erlangshen-DeBERTa-v2-186M-Chinese-SentencePiece', use_fast=False)\n",
    "model=AutoModelForMaskedLM.from_pretrained('IDEA-CCNL/Erlangshen-DeBERTa-v2-186M-Chinese-SentencePiece')\n",
    "text = '中国首都位于<mask>。'\n",
    "fillmask_pipe = FillMaskPipeline(model, tokenizer)\n",
    "print(fillmask_pipe(text, top_k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab33fc16-d25c-4929-9edc-416116497d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.9770157933235168, 'token': 3962, 'token_str': '漓', 'sequence': '桂 林 是 世 界 闻 名 的 旅 游 城 市, 它 有 漓 江 。'}, {'score': 0.006565024610608816, 'token': 256, 'token_str': '两', 'sequence': '桂 林 是 世 界 闻 名 的 旅 游 城 市, 它 有 两 江 。'}, {'score': 0.002794185420498252, 'token': 234, 'token_str': '三', 'sequence': '桂 林 是 世 界 闻 名 的 旅 游 城 市, 它 有 三 江 。'}, {'score': 0.0017296758014708757, 'token': 3390, 'token_str': '榕', 'sequence': '桂 林 是 世 界 闻 名 的 旅 游 城 市, 它 有 榕 江 。'}, {'score': 0.0012336598010733724, 'token': 3215, 'token_str': '柳', 'sequence': '桂 林 是 世 界 闻 名 的 旅 游 城 市, 它 有 柳 江 。'}, {'score': 0.0010069729760289192, 'token': 6458, 'token_str': '西', 'sequence': '桂 林 是 世 界 闻 名 的 旅 游 城 市, 它 有 西 江 。'}, {'score': 0.0009906459599733353, 'token': 6676, 'token_str': '象', 'sequence': '桂 林 是 世 界 闻 名 的 旅 游 城 市, 它 有 象 江 。'}, {'score': 0.0008100103586912155, 'token': 3260, 'token_str': '桂', 'sequence': '桂 林 是 世 界 闻 名 的 旅 游 城 市, 它 有 桂 江 。'}, {'score': 0.0003188226546626538, 'token': 8220, 'token_str': '龙', 'sequence': '桂 林 是 世 界 闻 名 的 旅 游 城 市, 它 有 龙 江 。'}, {'score': 0.0003103285562247038, 'token': 2996, 'token_str': '春', 'sequence': '桂 林 是 世 界 闻 名 的 旅 游 城 市, 它 有 春 江 。'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer, FillMaskPipeline\n",
    "import torch\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained('IDEA-CCNL/Erlangshen-DeBERTa-v2-320M-Chinese', use_fast=False)\n",
    "model=AutoModelForMaskedLM.from_pretrained('IDEA-CCNL/Erlangshen-DeBERTa-v2-320M-Chinese')\n",
    "text = '桂林是世界闻名的旅游城市,它有[MASK]江。'\n",
    "fillmask_pipe = FillMaskPipeline(model, tokenizer, device=0)\n",
    "print(fillmask_pipe(text, top_k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc13fc53-90c5-46ee-8c35-0c7176dd517c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
